{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "colab": {
      "name": "VAE_ML20M_reco_sys.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MO9jfCJ3wjzG",
        "Jx1O5-VowjzX"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetkrc/Recommender_systems/blob/master/Movie_Recommender/VAE_ML20M_reco_sys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULtwD7Icwjxj",
        "colab_type": "text"
      },
      "source": [
        "# Variational autoencoders for collaborative filtering "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMXUq7FQwjxk",
        "colab_type": "text"
      },
      "source": [
        "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
        "\n",
        "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8TzKto424Ru",
        "colab_type": "code",
        "outputId": "59309416-34a9-48dc-f856-5828a6b79d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install bottleneck"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bottleneck\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\n",
            "\r\u001b[K     |███▏                            | 10kB 20.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20kB 27.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 30kB 32.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 40kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 51kB 22.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 61kB 25.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 71kB 21.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 81kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 92kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 102kB 22.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from bottleneck) (1.16.4)\n",
            "Building wheels for collected packages: bottleneck\n",
            "  Building wheel for bottleneck (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bottleneck: filename=Bottleneck-1.2.1-cp27-cp27mu-linux_x86_64.whl size=313641 sha256=1bdbf311b01e70a0ff6785cc91a5442a6737bd14367cddad6b4c8ae3d7c35fce\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n",
            "Successfully built bottleneck\n",
            "Installing collected packages: bottleneck\n",
            "Successfully installed bottleneck-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h822R-E0wjxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sn\n",
        "sn.set()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
        "\n",
        "import bottleneck as bn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJNQ_LS0wjxn",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DSg0_eMwjxo",
        "colab_type": "text"
      },
      "source": [
        "We load the data and create train/validation/test splits following strong generalization: \n",
        "\n",
        "- We split all users into training/validation/test sets. \n",
        "\n",
        "- We train models using the entire click history of the training users. \n",
        "\n",
        "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtAN_VMGwjxo",
        "colab_type": "text"
      },
      "source": [
        "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EackL2eHw1e7",
        "colab_type": "code",
        "outputId": "2ffd1679-7c7f-464c-bcce-f26151b5ec69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-20m.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-20 06:34:16--  http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 198702078 (189M) [application/zip]\n",
            "Saving to: ‘ml-20m.zip’\n",
            "\n",
            "ml-20m.zip          100%[===================>] 189.50M  14.2MB/s    in 15s     \n",
            "\n",
            "2019-09-20 06:34:32 (12.8 MB/s) - ‘ml-20m.zip’ saved [198702078/198702078]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42R3lC_5w67w",
        "colab_type": "code",
        "outputId": "1b512cdc-5a95-43d9-dee5-357e4daf4939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!unzip /content/ml-20m.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/ml-20m.zip\n",
            "   creating: ml-20m/\n",
            "  inflating: ml-20m/genome-scores.csv  \n",
            "  inflating: ml-20m/genome-tags.csv  \n",
            "  inflating: ml-20m/links.csv        \n",
            "  inflating: ml-20m/movies.csv       \n",
            "  inflating: ml-20m/ratings.csv      \n",
            "  inflating: ml-20m/README.txt       \n",
            "  inflating: ml-20m/tags.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l3f2HzDwjxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
        "DATA_DIR = '/content/ml-20m'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADeLXUfZwjxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'), header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EexXCMqYwjxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# binarize the data (only keep ratings >= 4)\n",
        "raw_data = raw_data[raw_data['rating'] > 3.5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl5gJH2Jwjxv",
        "colab_type": "code",
        "outputId": "50bd2c4d-4e24-480d-cd4f-2d6d1cf7eeea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "raw_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1094785734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>223</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112485573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>253</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>260</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>293</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484703</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    userId  movieId  rating   timestamp\n",
              "6        1      151     4.0  1094785734\n",
              "7        1      223     4.0  1112485573\n",
              "8        1      253     4.0  1112484940\n",
              "9        1      260     4.0  1112484826\n",
              "10       1      293     4.0  1112484703"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud9_Rfz1wjxy",
        "colab_type": "text"
      },
      "source": [
        "### Data splitting procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0U5ScKYwjx3",
        "colab_type": "text"
      },
      "source": [
        "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
        "- Use all the items from the training users as item set\n",
        "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECFDhIqwwjx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
        "    count = playcount_groupbyid.size()\n",
        "    return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ6AVBsAwjx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'movieId')\n",
        "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
        "    \n",
        "    # Only keep the triplets for users who clicked on at least min_uc items\n",
        "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'userId')\n",
        "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
        "    \n",
        "    # Update both usercount and itemcount after filtering\n",
        "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
        "    return tp, usercount, itemcount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6Mc7X__wjx9",
        "colab_type": "text"
      },
      "source": [
        "Only keep items that are clicked on by at least 5 users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU2exm0awjyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVO9IAWHwjyD",
        "colab_type": "code",
        "outputId": "d4f21f23-ddd5-4781-aa30-5477558995d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
        "\n",
        "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
        "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After filtering, there are 9990682 watching events from 136677 users and 20720 movies (sparsity: 0.353%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UwVzfK1wjyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_uid = user_activity.index\n",
        "\n",
        "np.random.seed(98765)\n",
        "idx_perm = np.random.permutation(unique_uid.size)\n",
        "unique_uid = unique_uid[idx_perm]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbVVUperwjyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train/validation/test users\n",
        "n_users = unique_uid.size\n",
        "n_heldout_users = 10000\n",
        "\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
        "te_users = unique_uid[(n_users - n_heldout_users):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoaeeKGHwjyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7b5cm_iwjyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_sid = pd.unique(train_plays['movieId'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJaBfyWDwjyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRJbfUeNwjyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "\n",
        "if not os.path.exists(pro_dir):\n",
        "    os.makedirs(pro_dir)\n",
        "\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "    for sid in unique_sid:\n",
        "        f.write('%s\\n' % sid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhICnivnwjy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('userId')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
        "        n_items_u = len(group)\n",
        "\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "\n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(\"%d users sampled\" % i)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "    \n",
        "    return data_tr, data_te"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq9tkFurwjy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
        "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4knoIktKwjy8",
        "colab_type": "code",
        "outputId": "e14d84ef-0373-4ad9-c99c-16fbfd5c493d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TJ63mMgwjzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
        "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95cIdkMdwjzF",
        "colab_type": "code",
        "outputId": "cc5fa213-a6e2-46b3-f30a-e1430b938cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO9jfCJ3wjzG",
        "colab_type": "text"
      },
      "source": [
        "### Save the data into (user_index, item_index) format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0X1gkvbwjzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def numerize(tp):\n",
        "    uid = map(lambda x: profile2id[x], tp['userId'])\n",
        "    sid = map(lambda x: show2id[x], tp['movieId'])\n",
        "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEslgfjIwjzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = numerize(train_plays)\n",
        "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViCJ-pA1wjzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vad_data_tr = numerize(vad_plays_tr)\n",
        "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVUOwkmmwjzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vad_data_te = numerize(vad_plays_te)\n",
        "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZSxAfI1wjzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_tr = numerize(test_plays_tr)\n",
        "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7M2a0w7wjzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_te = numerize(test_plays_te)\n",
        "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbzxPaR2wjzW",
        "colab_type": "text"
      },
      "source": [
        "## Model definition and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_7z15KLwjzW",
        "colab_type": "text"
      },
      "source": [
        "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx1O5-VowjzX",
        "colab_type": "text"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtJxeo4FwjzY",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAxDpf2QwjzZ",
        "colab_type": "text"
      },
      "source": [
        "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
        "\n",
        "$$\n",
        "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
        "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9RjIXndwjzZ",
        "colab_type": "text"
      },
      "source": [
        "The objective for Multi-DAE for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
        "$$\n",
        "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CoHmLzCwjza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiDAE(object):\n",
        "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims is None:\n",
        "            self.q_dims = p_dims[::-1]\n",
        "        else:\n",
        "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        self.dims = self.q_dims + self.p_dims[1:]\n",
        "        \n",
        "        self.lam = lam\n",
        "        self.lr = lr\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        self.construct_placeholders()\n",
        "\n",
        "    def construct_placeholders(self):        \n",
        "        self.input_ph = tf.placeholder(\n",
        "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
        "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
        "\n",
        "    def build_graph(self):\n",
        "\n",
        "        self.construct_weights()\n",
        "\n",
        "        saver, logits = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        # per-user average negative log-likelihood\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph, axis=1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        reg_var = apply_regularization(reg, self.weights)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        loss = neg_ll + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('loss', loss)\n",
        "        merged = tf.summary.merge_all()\n",
        "        return saver, logits, loss, train_op, merged\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # construct forward graph        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return tf.train.Saver(), h\n",
        "\n",
        "    def construct_weights(self):\n",
        "\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        \n",
        "        # define weights\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
        "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_{}\".format(i+1)\n",
        "            \n",
        "            self.weights.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7dkrsOMwjzb",
        "colab_type": "text"
      },
      "source": [
        "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
        "$$\n",
        "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESI9mh7iwjzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiVAE(MultiDAE):\n",
        "\n",
        "    def construct_placeholders(self):\n",
        "        super(MultiVAE, self).construct_placeholders()\n",
        "\n",
        "        # placeholders with default values when scoring\n",
        "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
        "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
        "        \n",
        "    def build_graph(self):\n",
        "        self._construct_weights()\n",
        "\n",
        "        saver, logits, KL = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph,\n",
        "            axis=-1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        \n",
        "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('KL', KL)\n",
        "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
        "        merged = tf.summary.merge_all()\n",
        "\n",
        "        return saver, logits, neg_ELBO, train_op, merged\n",
        "    \n",
        "    def q_graph(self):\n",
        "        mu_q, std_q, KL = None, None, None\n",
        "        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_q) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "            else:\n",
        "                mu_q = h[:, :self.q_dims[-1]]\n",
        "                logvar_q = h[:, self.q_dims[-1]:]\n",
        "\n",
        "                std_q = tf.exp(0.5 * logvar_q)\n",
        "                KL = tf.reduce_mean(tf.reduce_sum(\n",
        "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
        "        return mu_q, std_q, KL\n",
        "\n",
        "    def p_graph(self, z):\n",
        "        h = z\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_p) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # q-network\n",
        "        mu_q, std_q, KL = self.q_graph()\n",
        "        epsilon = tf.random_normal(tf.shape(std_q))\n",
        "\n",
        "        sampled_z = mu_q + self.is_training_ph *\\\n",
        "            epsilon * std_q\n",
        "\n",
        "        # p-network\n",
        "        logits = self.p_graph(sampled_z)\n",
        "        \n",
        "        return tf.train.Saver(), logits, KL\n",
        "\n",
        "    def _construct_weights(self):\n",
        "        self.weights_q, self.biases_q = [], []\n",
        "        \n",
        "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
        "            if i == len(self.q_dims[:-1]) - 1:\n",
        "                # we need two sets of parameters for mean and variance,\n",
        "                # respectively\n",
        "                d_out *= 2\n",
        "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_q_{}\".format(i+1)\n",
        "            \n",
        "            self.weights_q.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_q.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
        "            \n",
        "        self.weights_p, self.biases_p = [], []\n",
        "\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
        "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_p_{}\".format(i+1)\n",
        "            self.weights_p.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_p.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_p[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brt5nPgywjzd",
        "colab_type": "text"
      },
      "source": [
        "### Training/validation data, hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxtS99T5wjze",
        "colab_type": "text"
      },
      "source": [
        "Load the pre-processed training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skiVdABHwjze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_sid = list()\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
        "    for line in f:\n",
        "        unique_sid.append(line.strip())\n",
        "\n",
        "n_items = len(unique_sid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmp5gT9xwjzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_train_data(csv_file):\n",
        "    tp = pd.read_csv(csv_file)\n",
        "    n_users = tp['uid'].max() + 1\n",
        "\n",
        "    rows, cols = tp['uid'], tp['sid']\n",
        "    data = sparse.csr_matrix((np.ones_like(rows),\n",
        "                             (rows, cols)), dtype='float64',\n",
        "                             shape=(n_users, n_items))\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKlKGq5Gwjzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMA_Rsavwjzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
        "    tp_tr = pd.read_csv(csv_file_tr)\n",
        "    tp_te = pd.read_csv(csv_file_te)\n",
        "\n",
        "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
        "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
        "\n",
        "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
        "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
        "\n",
        "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
        "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
        "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    return data_tr, data_te"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAcbkXe6wjzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
        "                                           os.path.join(pro_dir, 'validation_te.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq26M4Newjzp",
        "colab_type": "text"
      },
      "source": [
        "Set up training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUf6cG47wjzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = train_data.shape[0]\n",
        "idxlist = range(N)\n",
        "\n",
        "# training batch size\n",
        "batch_size = 500\n",
        "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
        "\n",
        "N_vad = vad_data_tr.shape[0]\n",
        "idxlist_vad = range(N_vad)\n",
        "\n",
        "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
        "batch_size_vad = 2000\n",
        "\n",
        "# the total number of gradient updates for annealing\n",
        "total_anneal_steps = 200000\n",
        "# largest annealing parameter\n",
        "anneal_cap = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBcipZzAwjzs",
        "colab_type": "text"
      },
      "source": [
        "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi0N17ggwjzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    '''\n",
        "    normalized discounted cumulative gain@k for binary relevance\n",
        "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
        "    '''\n",
        "    batch_users = X_pred.shape[0]\n",
        "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                       idx_topk_part[:, :k]]\n",
        "    idx_part = np.argsort(-topk_part, axis=1)\n",
        "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
        "    # topk predicted score\n",
        "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "    # build the discount template\n",
        "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
        "\n",
        "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                         idx_topk].toarray() * tp).sum(axis=1)\n",
        "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
        "                     for n in heldout_batch.getnnz(axis=1)])\n",
        "    return DCG / IDCG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSht8b_Mwjzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    batch_users = X_pred.shape[0]\n",
        "\n",
        "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
        "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
        "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
        "\n",
        "    X_true_binary = (heldout_batch > 0).toarray()\n",
        "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
        "        np.float32)\n",
        "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
        "    return recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jLz6Hvcwjz1",
        "colab_type": "text"
      },
      "source": [
        "### Train a Multi-VAE^{PR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPfN6dCuwjz1",
        "colab_type": "text"
      },
      "source": [
        "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3NiUu0Owjz1",
        "colab_type": "text"
      },
      "source": [
        "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlHLTOE7wjz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_dims = [200, 600, n_items]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVawI6USwjz7",
        "colab_type": "code",
        "outputId": "152ca9e2-3a02-4217-8ef5-092d981d2e93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0920 06:35:56.470362 140667863984000 deprecation.py:506] From <ipython-input-31-318b0755b4c1>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0920 06:35:56.676098 140667863984000 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1205: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxcrIsZCwjz8",
        "colab_type": "text"
      },
      "source": [
        "Set up logging and checkpoint directory\n",
        "\n",
        "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
        "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugm64yc6wjz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpP1ahjawjz_",
        "colab_type": "code",
        "outputId": "9ec9c534-6d7d-4f9f-d956-2223dffb36c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "log_dir = '/volmount/log/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log directory: /volmount/log/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqf_6fX2wj0C",
        "colab_type": "code",
        "outputId": "ab0b56b9-82af-440d-cd7e-b40e6156d678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /volmount/chkpt/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVRuGBKvwj0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDco6eJ3wj0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ndcgs_vad = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "\n",
        "    update_count = 0.0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            if total_anneal_steps > 0:\n",
        "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "            else:\n",
        "                anneal = anneal_cap\n",
        "            \n",
        "            feed_dict = {vae.input_ph: X, \n",
        "                         vae.keep_prob_ph: 0.5, \n",
        "                         vae.anneal_ph: anneal,\n",
        "                         vae.is_training_ph: 1}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, \n",
        "                                           global_step=epoch * batches_per_epoch + bnum) \n",
        "            \n",
        "            update_count += 1\n",
        "        \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        summary_writer.add_summary(merged_valid_val, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        print \"the epoch number is \" + str(epoch)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9R4JrLfwj0H",
        "colab_type": "code",
        "outputId": "ff4bf11e-ae1b-4790-b70c-f09a7b5d47e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAADbCAYAAADUHN+5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjF5KlW1wj0J",
        "colab_type": "text"
      },
      "source": [
        "### Load the test data and compute test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQzth0swwj0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_tr, test_data_te = load_tr_te_data(\n",
        "    os.path.join(pro_dir, 'test_tr.csv'),\n",
        "    os.path.join(pro_dir, 'test_te.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbAU7-Eawj0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_test = test_data_tr.shape[0]\n",
        "idxlist_test = range(N_test)\n",
        "\n",
        "batch_size_test = 2000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZioHxiiwj0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0)\n",
        "saver, logits_var, _, _, _ = vae.build_graph()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejkTi__Iwj0O",
        "colab_type": "text"
      },
      "source": [
        "Load the best performing model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A77jCcMMwj0O",
        "colab_type": "code",
        "outputId": "bd6613c8-cfe9-431c-97e6-752be470c7a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /volmount/chkpt/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdrFw0j1wj0R",
        "colab_type": "code",
        "outputId": "5430cd36-3b03-4833-87f8-141616f8c013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "\n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "    \n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0920 09:03:53.178450 140667863984000 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiZWtkmkwj0S",
        "colab_type": "code",
        "outputId": "984be108-342f-48fd-e874-d69c052185bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NDCG@100=0.42485 (0.00210)\n",
            "Test Recall@20=0.39287 (0.00269)\n",
            "Test Recall@50=0.53552 (0.00285)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv6XPe5Zwj0U",
        "colab_type": "text"
      },
      "source": [
        "### Train a Multi-DAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCimp2f3wj0U",
        "colab_type": "text"
      },
      "source": [
        "The generative function is a [200 -> n_items] MLP, thus the overall architecture for the Multi-DAE is [n_items -> 200 -> n_items]. We find this architecture achieves better validation NDCG@100 than the [n_items -> 600 -> 200 -> 600 -> n_items] architecture as used in Multi-VAE^{PR}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCDLUT35wj0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_dims = [200, n_items]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExjdcevOwj0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dae = MultiDAE(p_dims, lam=0.01 / batch_size, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = dae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5Wk_vRRwj0X",
        "colab_type": "text"
      },
      "source": [
        "Set up logging and checkpoint directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thMztQeQwj0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in dae.dims[1:-1]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FuR8fC9wj0Z",
        "colab_type": "code",
        "outputId": "8acde33f-91b2-4665-8d5f-bfd3648ed8e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "log_dir = '/volmount/log/ml-20m/DAE/{}'.format(arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log directory: /volmount/log/ml-20m/DAE/I-200-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXYpojsywj0a",
        "colab_type": "code",
        "outputId": "45986b98-af2f-4966-de68-d7314d624c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chkpt_dir = '/volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /volmount/chkpt/ml-20m/DAE/I-200-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq-d99kTwj0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4CCaodYwj0d",
        "colab_type": "code",
        "outputId": "d61fb399-269c-4353-e25f-e22fb839fd4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ndcgs_vad = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            feed_dict = {dae.input_ph: X, \n",
        "                         dae.keep_prob_ph: 0.5}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
        "                    \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        summary_writer.add_summary(merged_valid_val, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        print \"epoch number \" + str(epoch)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number 0\n",
            "epoch number 1\n",
            "epoch number 2\n",
            "epoch number 3\n",
            "epoch number 4\n",
            "epoch number 5\n",
            "epoch number 6\n",
            "epoch number 7\n",
            "epoch number 8\n",
            "epoch number 9\n",
            "epoch number 10\n",
            "epoch number 11\n",
            "epoch number 12\n",
            "epoch number 13\n",
            "epoch number 14\n",
            "epoch number 15\n",
            "epoch number 16\n",
            "epoch number 17\n",
            "epoch number 18\n",
            "epoch number 19\n",
            "epoch number 20\n",
            "epoch number 21\n",
            "epoch number 22\n",
            "epoch number 23\n",
            "epoch number 24\n",
            "epoch number 25\n",
            "epoch number 26\n",
            "epoch number 27\n",
            "epoch number 28\n",
            "epoch number 29\n",
            "epoch number 30\n",
            "epoch number 31\n",
            "epoch number 32\n",
            "epoch number 33\n",
            "epoch number 34\n",
            "epoch number 35\n",
            "epoch number 36\n",
            "epoch number 37\n",
            "epoch number 38\n",
            "epoch number 39\n",
            "epoch number 40\n",
            "epoch number 41\n",
            "epoch number 42\n",
            "epoch number 43\n",
            "epoch number 44\n",
            "epoch number 45\n",
            "epoch number 46\n",
            "epoch number 47\n",
            "epoch number 48\n",
            "epoch number 49\n",
            "epoch number 50\n",
            "epoch number 51\n",
            "epoch number 52\n",
            "epoch number 53\n",
            "epoch number 54\n",
            "epoch number 55\n",
            "epoch number 56\n",
            "epoch number 57\n",
            "epoch number 58\n",
            "epoch number 59\n",
            "epoch number 60\n",
            "epoch number 61\n",
            "epoch number 62\n",
            "epoch number 63\n",
            "epoch number 64\n",
            "epoch number 65\n",
            "epoch number 66\n",
            "epoch number 67\n",
            "epoch number 68\n",
            "epoch number 69\n",
            "epoch number 70\n",
            "epoch number 71\n",
            "epoch number 72\n",
            "epoch number 73\n",
            "epoch number 74\n",
            "epoch number 75\n",
            "epoch number 76\n",
            "epoch number 77\n",
            "epoch number 78\n",
            "epoch number 79\n",
            "epoch number 80\n",
            "epoch number 81\n",
            "epoch number 82\n",
            "epoch number 83\n",
            "epoch number 84\n",
            "epoch number 85\n",
            "epoch number 86\n",
            "epoch number 87\n",
            "epoch number 88\n",
            "epoch number 89\n",
            "epoch number 90\n",
            "epoch number 91\n",
            "epoch number 92\n",
            "epoch number 93\n",
            "epoch number 94\n",
            "epoch number 95\n",
            "epoch number 96\n",
            "epoch number 97\n",
            "epoch number 98\n",
            "epoch number 99\n",
            "epoch number 100\n",
            "epoch number 101\n",
            "epoch number 102\n",
            "epoch number 103\n",
            "epoch number 104\n",
            "epoch number 105\n",
            "epoch number 106\n",
            "epoch number 107\n",
            "epoch number 108\n",
            "epoch number 109\n",
            "epoch number 110\n",
            "epoch number 111\n",
            "epoch number 112\n",
            "epoch number 113\n",
            "epoch number 114\n",
            "epoch number 115\n",
            "epoch number 116\n",
            "epoch number 117\n",
            "epoch number 118\n",
            "epoch number 119\n",
            "epoch number 120\n",
            "epoch number 121\n",
            "epoch number 122\n",
            "epoch number 123\n",
            "epoch number 124\n",
            "epoch number 125\n",
            "epoch number 126\n",
            "epoch number 127\n",
            "epoch number 128\n",
            "epoch number 129\n",
            "epoch number 130\n",
            "epoch number 131\n",
            "epoch number 132\n",
            "epoch number 133\n",
            "epoch number 134\n",
            "epoch number 135\n",
            "epoch number 136\n",
            "epoch number 137\n",
            "epoch number 138\n",
            "epoch number 139\n",
            "epoch number 140\n",
            "epoch number 141\n",
            "epoch number 142\n",
            "epoch number 143\n",
            "epoch number 144\n",
            "epoch number 145\n",
            "epoch number 146\n",
            "epoch number 147\n",
            "epoch number 148\n",
            "epoch number 149\n",
            "epoch number 150\n",
            "epoch number 151\n",
            "epoch number 152\n",
            "epoch number 153\n",
            "epoch number 154\n",
            "epoch number 155\n",
            "epoch number 156\n",
            "epoch number 157\n",
            "epoch number 158\n",
            "epoch number 159\n",
            "epoch number 160\n",
            "epoch number 161\n",
            "epoch number 162\n",
            "epoch number 163\n",
            "epoch number 164\n",
            "epoch number 165\n",
            "epoch number 166\n",
            "epoch number 167\n",
            "epoch number 168\n",
            "epoch number 169\n",
            "epoch number 170\n",
            "epoch number 171\n",
            "epoch number 172\n",
            "epoch number 173\n",
            "epoch number 174\n",
            "epoch number 175\n",
            "epoch number 176\n",
            "epoch number 177\n",
            "epoch number 178\n",
            "epoch number 179\n",
            "epoch number 180\n",
            "epoch number 181\n",
            "epoch number 182\n",
            "epoch number 183\n",
            "epoch number 184\n",
            "epoch number 185\n",
            "epoch number 186\n",
            "epoch number 187\n",
            "epoch number 188\n",
            "epoch number 189\n",
            "epoch number 190\n",
            "epoch number 191\n",
            "epoch number 192\n",
            "epoch number 193\n",
            "epoch number 194\n",
            "epoch number 195\n",
            "epoch number 196\n",
            "epoch number 197\n",
            "epoch number 198\n",
            "epoch number 199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkACYkqSwj0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "f0f45043-732a-4206-c5dd-2e89d071768d"
      },
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAADbCAYAAADUHN+5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfgyl1xDwj0f",
        "colab_type": "text"
      },
      "source": [
        "### Compute test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M32TmM01wj0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dae = MultiDAE(p_dims, lam=0.01 / batch_size)\n",
        "saver, logits_var, _, _, _ = dae.build_graph()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DL9C3p1wj0h",
        "colab_type": "text"
      },
      "source": [
        "Load the best performing model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYoKhx5jwj0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97bbacfb-4720-40e2-b544-e3d8d76b79c3"
      },
      "source": [
        "chkpt_dir = '/volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /volmount/chkpt/ml-20m/DAE/I-200-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-bGK5Nmwj0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.Session() as sess:    \n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "    \n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "\n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yIsLzdmwj0l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "dae68417-3f4a-4309-eaaa-8b0ff5a0deae"
      },
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NDCG@100=0.42013 (0.00212)\n",
            "Test Recall@20=0.38734 (0.00267)\n",
            "Test Recall@50=0.52379 (0.00285)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}